---
draft: false
date: 2023-04-16
authors:
  - cameronpresley
description: >
  Measuring Effectiveness - The Pitfall of a Single Data Point

categories:
  - Leadership

hide:
  - toc
---

# Measuring Effectiveness: The Pitfall of a Single Data Point

At some point in your leadership journey, you're going to get asked if someone is "doing well" or "if they're effective". 

At first glance, this is a fair question to ask as you want to make sure that you're growing and leveling up your team.

However, this begs the question, _What does effectiveness look like?_

Is it the number of pull requests? The number of stories completed in a sprint? The number of bugs in production? Test coverage?

The trap that leaders fall into is that they're always on the hunt for the one metric that can give a definitive statement if someone is doing well.

(which makes me think of...)

<figure markdown>
![The One Ring from Lord of the Rings](../images/one-ring.png)
<figcaption>One metric to rule them all, one metric to measure them, one metric to bring them all and in efficiency, bind them.<p><a href="https://lotr.fandom.com/wiki/One_Ring">Source</a></p></figcaption>
</figure>

However, the problem with using a metric, is that it'll cease being an effective measurement (see [Goodhart's Law](https://en.wikipedia.org/wiki/Goodhart%27s_law)).

For example, if we measure effectiveness by the number of completed pull requests, then what's stopping someone from creating hundreds of single line pull requests that don't accomplish anything?

Another way to think about the problem is that when we look at a single data point, it's like reading a sentence from a book and then making a judgement what kind of book it is.

Remember, our quest is to answer "what does effectiveness look like"?

To me, we can measure effectiveness holistically by checking out the following three areas:

- Understanding the problem (e.g. why are we doing this?)
- Understanding the system (e.g. how are we doing this?)
- Understanding the people (e.g. whom are we doing this with?)


The main strength of this approach is that it will help you gain a better understanding of where your people spend their time and what their naturally interested in. This in turn helps you give better feedback and coach them forward.

## Understanding the Problem

To be successful, we have to understand the problem that's being solved. Without this basis, it's impossible to build the right solutions or even ask the right questions. 

In other words, how much domain knowledge do they have and how comfortable are they with the knowledge?

Given that some people are vocal and others are reserved, there are different ways to measure this. 

First, you can look at the questions that are being asked (through chats, comments on the ticket, in meetings, pull request comments, etc...).

Second, you can look at feedback on the solution. Did they design it with domain knowledge in mind? Were edge cases or workflows handled? Or did someone need to let them know about those workflows?

Third, how are they handling support issues? In order to understand why the problem is a problem, you've got to understand the problem domain. Someone doing well here will understand why its a problem and what the expected behavior should be.

No one is going to be an expert in the problem domain, but you should see the amount of knowledge increasing over time. In addition, you're going to want to see that person sharing their knowledge and leveling up others.

## Understanding the System

There's always a push to deliver more things and in order to do that, we have to understand the current system, its limitations, what's easy vs what's hard and from these constraints, determine the correct path to take.

In addition, once the system is live, we need to support it. If we don't know the moving parts, what it interacts with, how it's used, we're going to have a bad time.

Similar to [understanding the problem](#understanding-the-problem), we can measure system knowledge based on questions that are being asked. In particular, I've found pull request comments and code reviews to be insightful on someone's knowledge of the system. 

Another way to gauge system knowledge is by looking at how the person handles support requests. If you can troubleshoot the system, figure out the problem, and create a fix, by definition, you have to have a solid understanding of the system.

## Understanding the People

The third part of being effective is that you can work with those around you to be successful. Most people think engineering is a solitary line of work and when it comes to the development phase, that can be true.

However, in reality, it's engineers working with others to design, develop, and iterate on a solution and this can only happen when working with others. As such, building these relationships are paramount to being successful.

!!! quote ""
    If you want to go fast, go alone. If you want to go far, go together.

For this part, we're measuring how we get along with others and can we work as a team. Measuring team cohesion can be its own post, but for right now, we can focus on asking our peers and those we work with on how those relationships are.

Some companies have an internal recognition system where you can recognize someone for going above and beyond, usually points or other reward. I keep track of these for my team so not only I can prop them out when they receive the award, but also during 1:1s and review time. 

## Wrapping Up

In order to determine how effective someone is, I recommend measuring the following areas:

- Understanding the problem (e.g. why are we doing this?)
- Understanding the system (e.g. how are we doing this?)
- Understanding the people (e.g. whom are we doing this with?)

We can measure these through interactions, comments on stories and pull requests, handling support requests, and by asking our peers.

By having this knowledge, we can make a better assessment on how someone is doing and where we can coach to help them improve.